# アイデアメモ

## 実装済み
C:\Users\saiha\.gemini\GEMINI.md などのAIエージェントの汎用的にコンテストが注入さるテキストに、FunctionStoreを使うように指示する文章を.md形式で注入。
（例）
- コーティングやプログラミングの作業時には、MCPサーバのFunctionStoreを活用してください。

---

## 以下は対処済み

あなたはこの分野の専門家です。ＭＣＰサーバの機能整理とＬＬＭ（GeminiAPIとllama-cpp-pythonのローカルＬＬＭを活用した検索＆取り出し機能の一体化と高度化の計画を立案してください。そして日本語で詳しく解説してください。

具体的にはMCPツールの「inject_local_package」「get_function」「search_functions」を統合して、getだけにする。その理由はこれらのMCPツールは３つに分ける必要がないからです。そのために１つに統合します。

そのgetにはCursorなどのAIエージェントからどんな機能のものが欲しいのかっていうのを自然言語で受け付け、内部でserchを行い、LLMを使って目的に沿っているのかの判定を行い、injectを自動で実行するまでやってしまってどのような関数をどのようなディレクトリパスに配置したのかっていう情報を返り値としてAIエージェントに送るまでやってほうが良いのでは？これのほうがAIエージェントのリソースを使わないと思いまし、最高にとがった機能かつ良いUXだと思います。
また、AIエージェントに送る内容は、何をどこに配置したのかっていう情報と、その配置したものがどんなものなのかっていう情報としてメタデータにある関数の説明文を送ればよいと思います。これから毎回LLMで生成する必要がないと思います。

---

あなたはホリエモンです。以下の意見について評価してください。
FuctionStoreに登録する関数のセキュリティと品質の担保は、品質が高いことに越したことはないのですが、FuctionStoreの目的はAIエージェントのための再開発防止のMCPのために下書きとなる機能の提供ロジックを優先します。このFunctionStoreに登録されている関数の品質を全体的に引き上げるというよりかは、検索機能を拡充し品質に低いものがヒットしにくくなるようにしたほうがアプローチとしては良いと考えます。なので、ひとまず静的なチェックの拡張とそのチェック結果を検索順位に反映するロジックが優先だと考えます。その理由は高品質でないとFunctionStoreに保存しませんっているロジックだとUXを致命的に損なうからです。またLLMで自動修正をするにしても基本的にCursorなどのAIエージェントからの利用となるので、組み込むLLMより賢い場合が大半のために自動修復機能はあえて実装しないことを提案します。